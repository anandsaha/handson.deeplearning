{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(object):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, lr, epochs, bs):\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.bs = bs\n",
    "        \n",
    "        self.x = tf.placeholder(dtype=tf.float32, shape=[None, input_dim], name='x')\n",
    "        \n",
    "        with tf.name_scope('encoder'):\n",
    "            weights = tf.Variable(tf.random_normal([input_dim, hidden_dim]), name='weights')\n",
    "            biases = tf.Variable(tf.zeros([hidden_dim]), name='biases')\n",
    "            encode = tf.nn.tanh(tf.matmul(self.x, weights) + biases)\n",
    "        \n",
    "        with tf.name_scope('decoder'):\n",
    "            weights = tf.Variable(tf.random_normal([hidden_dim, input_dim]), name='weights')\n",
    "            biases = tf.Variable(tf.zeros([input_dim]), name='biases')\n",
    "            decode = tf.matmul(encode, weights) + biases\n",
    "            \n",
    "        self.encode = encode\n",
    "        self.decode = decode\n",
    "        \n",
    "        self.loss = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(self.x, self.decode))))\n",
    "        self.train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def train(self, data):\n",
    "        num_samples = len(data)\n",
    "        num_batches = int(num_samples / self.bs)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(self.epochs):\n",
    "                for j in range(num_batches):\n",
    "                    batch = data[np.random.choice(num_samples, self.bs, replace= False)]\n",
    "                    l, _ = sess.run([self.loss, self.train_op], feed_dict={self.x: batch})\n",
    "                if i%10 == 0:\n",
    "                    print('epoch: {0}, loss={1}'.format(i, l))\n",
    "                \n",
    "            self.saver.save(sess, 'autoencoder_model.ckpt')\n",
    "            \n",
    "    def test(self, data):\n",
    "        with tf.Session() as sess:\n",
    "            self.saver.restore(sess, './autoencoder_model.ckpt')\n",
    "            hidden, reconstructed = sess.run([self.encode, self.decode], feed_dict={self.x: data})\n",
    "        \n",
    "        print( 'input ', data)\n",
    "        print( 'compressed' , hidden)\n",
    "        print( 'reconstructed' , reconstructed)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=4.402854919433594\n",
      "epoch: 10, loss=1.5729666948318481\n",
      "epoch: 20, loss=0.6488809585571289\n",
      "epoch: 30, loss=0.4366246461868286\n",
      "epoch: 40, loss=0.3858313262462616\n",
      "epoch: 50, loss=0.41962137818336487\n",
      "epoch: 60, loss=0.3147802948951721\n",
      "epoch: 70, loss=0.40170150995254517\n",
      "epoch: 80, loss=0.2726631462574005\n",
      "epoch: 90, loss=0.26577094197273254\n",
      "epoch: 100, loss=0.3993598222732544\n",
      "epoch: 110, loss=0.3006899654865265\n",
      "epoch: 120, loss=0.2344166785478592\n",
      "epoch: 130, loss=0.3055359423160553\n",
      "epoch: 140, loss=0.32929331064224243\n",
      "epoch: 150, loss=0.30390119552612305\n",
      "epoch: 160, loss=0.21616226434707642\n",
      "epoch: 170, loss=0.2644341289997101\n",
      "epoch: 180, loss=0.1692265421152115\n",
      "epoch: 190, loss=0.23742546141147614\n",
      "epoch: 200, loss=0.23149912059307098\n",
      "epoch: 210, loss=0.2001902163028717\n",
      "epoch: 220, loss=0.2280314564704895\n",
      "epoch: 230, loss=0.2998230755329132\n",
      "epoch: 240, loss=0.26532673835754395\n",
      "epoch: 250, loss=0.19614939391613007\n",
      "epoch: 260, loss=0.28185975551605225\n",
      "epoch: 270, loss=0.17649967968463898\n",
      "epoch: 280, loss=0.22279547154903412\n",
      "epoch: 290, loss=0.17977653443813324\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "hidden_dim=2\n",
    "data = datasets.load_iris().data\n",
    "input_dim = len(data[0])\n",
    "ae = AutoEncoder(input_dim, hidden_dim, 0.01, 300, 10)\n",
    "ae.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./autoencoder_model.ckpt\n",
      "input  [[8, 4, 6, 2]]\n",
      "compressed [[-0.96621865 -0.75487101]]\n",
      "reconstructed [[ 7.13904095  3.483845    5.89659595  2.07307124]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.13904095,  3.483845  ,  5.89659595,  2.07307124]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.test([[8, 4, 6, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
