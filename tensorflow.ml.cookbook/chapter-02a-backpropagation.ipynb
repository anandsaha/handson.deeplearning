{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step #25 A = [ 6.30272532]\n",
      "Loss = [ 22.84630966]\n",
      "\n",
      "Step #50 A = [ 8.63738537]\n",
      "Loss = [ 1.77492213]\n",
      "\n",
      "Step #75 A = [ 9.51745605]\n",
      "Loss = [  1.72653454e-05]\n",
      "\n",
      "Step #100 A = [ 9.64468288]\n",
      "Loss = [ 0.2176234]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy dataset\n",
    "num_instances = 100\n",
    "x_data = np.random.normal(1, 0.1, num_instances)\n",
    "y_data = np.repeat(10., num_instances)\n",
    "\n",
    "# The placeholders\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[1], name='x')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[1], name='y')\n",
    "\n",
    "# The parameter\n",
    "A = tf.Variable(tf.random_normal(shape=[1]), 'A')\n",
    "\n",
    "# The operation\n",
    "out = tf.multiply(x, A, name='multiply')\n",
    "\n",
    "# The loss\n",
    "loss = tf.square(out - y, name='loss')\n",
    "\n",
    "# The optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.02)\n",
    "train_step = opt.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(100):\n",
    "        rand_index = np.random.choice(num_instances)\n",
    "        x_rand = [x_data[rand_index]]\n",
    "        y_rand = [y_data[rand_index]]\n",
    "        op = sess.run(train_step, feed_dict={x: x_rand, y: y_rand})\n",
    "        \n",
    "        if (i+1)%25 == 0:\n",
    "            print('\\nStep #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "            print('Loss = ' + str(sess.run(loss, feed_dict={x: x_rand, y: y_rand})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step #500 A = [ 7.23542023]\n",
      "Loss = [[ 5.83095169]]\n",
      "\n",
      "Step #1000 A = [ 4.8474288]\n",
      "Loss = [[ 2.85639954]]\n",
      "\n",
      "Step #1500 A = [ 2.4942019]\n",
      "Loss = [[ 1.67046142]]\n",
      "\n",
      "Step #2000 A = [ 0.94248766]\n",
      "Loss = [[ 0.05283167]]\n",
      "\n",
      "Step #2500 A = [ 0.07322872]\n",
      "Loss = [[ 0.03926991]]\n",
      "\n",
      "Step #3000 A = [-0.44462091]\n",
      "Loss = [[ 0.27187258]]\n",
      "\n",
      "Step #3500 A = [-0.63149375]\n",
      "Loss = [[ 0.38703641]]\n",
      "\n",
      "Step #4000 A = [-0.74346507]\n",
      "Loss = [[ 0.07089114]]\n",
      "\n",
      "Step #4500 A = [-0.8463487]\n",
      "Loss = [[ 0.13661754]]\n",
      "\n",
      "Step #5000 A = [-0.9520095]\n",
      "Loss = [[ 0.08764885]]\n",
      "\n",
      "Step #5500 A = [-0.99335623]\n",
      "Loss = [[ 0.39267752]]\n",
      "\n",
      "Step #6000 A = [-1.04970276]\n",
      "Loss = [[ 0.10110707]]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy dataset \n",
    "num_instances = 50\n",
    "ax = np.random.normal(-1, 1, num_instances)\n",
    "bx = np.random.normal(3, 1, num_instances)\n",
    "x_data = np.hstack([ax, bx])\n",
    "\n",
    "ay = np.repeat(0., num_instances)\n",
    "by = np.repeat(1., num_instances)\n",
    "y_data = np.hstack([ay, by])\n",
    "\n",
    "# Placeholders\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[1])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[1])\n",
    "\n",
    "# The parameter\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))\n",
    "\n",
    "# The operation\n",
    "out = tf.add(x, A)\n",
    "\n",
    "# Add a dimension for the batch number\n",
    "out_expanded = tf.expand_dims(out, 0)\n",
    "y_expanded = tf.expand_dims(y, 0)\n",
    "\n",
    "# The loss and the optimizer\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_expanded, logits=out_expanded)\n",
    "opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = opt.minimize(xentropy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(6000):\n",
    "        rand_index = np.random.choice(num_instances+num_instances)\n",
    "        x_rand = [x_data[rand_index]]\n",
    "        y_rand = [y_data[rand_index]]\n",
    "        op = sess.run(train_step, feed_dict={x: x_rand, y: y_rand})\n",
    "        \n",
    "        if (i+1)%500 == 0:\n",
    "            print('\\nStep #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "            print('Loss = ' + str(sess.run(xentropy, feed_dict={x: x_rand, y: y_rand})))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
